{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzJPDnyziMlW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# Project root configuration\n",
        "PROJECT_ROOT = Path(__file__).parent\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(PROJECT_ROOT / 'wmap_project.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configuration management\n",
        "class ProjectConfig:\n",
        "    \"\"\"\n",
        "    Centralized configuration for the WMAP project\n",
        "    \"\"\"\n",
        "    # Database configuration\n",
        "    DATABASE_CONFIG = {\n",
        "        'host': 'localhost',\n",
        "        'database': 'wmap_database',\n",
        "        'user': 'astronomical_user',\n",
        "        'password': 'secure_password'\n",
        "    }\n",
        "\n",
        "    # Data source paths\n",
        "    DATA_SOURCES = {\n",
        "        'wmap_raw': PROJECT_ROOT / 'data' / 'raw',\n",
        "        'wmap_processed': PROJECT_ROOT / 'data' / 'processed',\n",
        "    }\n",
        "\n",
        "    # Ensure data directories exist\n",
        "    @classmethod\n",
        "    def setup_directories(cls):\n",
        "        for path in cls.DATA_SOURCES.values():\n",
        "            path.mkdir(parents=True, exist_ok=True)\n",
        "        logger.info(\"Data directories initialized\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main entry point for the WMAP Project\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Setup project directories\n",
        "        ProjectConfig.setup_directories()\n",
        "\n",
        "        # Import and run main project components\n",
        "        from src.data_acquisition import download_wmap_data\n",
        "        from src.database_manager import DatabaseManager\n",
        "        from src.data_analysis import perform_analysis\n",
        "\n",
        "        # Download WMAP data\n",
        "        download_wmap_data()\n",
        "\n",
        "        # Initialize database\n",
        "        db_manager = DatabaseManager(ProjectConfig.DATABASE_CONFIG)\n",
        "        db_manager.create_schema()\n",
        "        db_manager.import_data()\n",
        "\n",
        "        # Perform scientific analysis\n",
        "        perform_analysis()\n",
        "\n",
        "        logger.info(\"WMAP Project completed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Project execution failed: {e}\", exc_info=True)\n",
        "        sys.exit(1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import logging\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def download_wmap_data(output_dir='data/raw'):\n",
        "    \"\"\"\n",
        "    Download WMAP dataset from NASA's repository\n",
        "\n",
        "    Args:\n",
        "        output_dir (str): Directory to save downloaded data\n",
        "    \"\"\"\n",
        "    # WMAP data sources (example URLs - replace with actual NASA links)\n",
        "    wmap_data_sources = {\n",
        "        'temperature_map': 'https://lambda.gsfc.nasa.gov/data/map/dr5/sky_maps/temperature_map.fits',\n",
        "        'polarization_map': 'https://lambda.gsfc.nasa.gov/data/map/dr5/sky_maps/polarization_map.fits',\n",
        "        'cosmological_parameters': 'https://lambda.gsfc.nasa.gov/data/map/dr5/parameters/cosmological_parameters.csv'\n",
        "    }\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download each data source\n",
        "    for name, url in wmap_data_sources.items():\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Save file\n",
        "            file_path = output_path / f'{name}.fits' if name != 'cosmological_parameters' else output_path / f'{name}.csv'\n",
        "\n",
        "            with open(file_path, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "\n",
        "            logger.info(f'Successfully downloaded {name}')\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            logger.error(f'Error downloading {name}: {e}')\n",
        "\n",
        "def preprocess_wmap_data(input_dir='data/raw', output_dir='data/processed'):\n",
        "    \"\"\"\n",
        "    Preprocess downloaded WMAP data\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Directory with raw data\n",
        "        output_dir (str): Directory to save processed data\n",
        "    \"\"\"\n",
        "    import astropy.io.fits as fits\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Process temperature map\n",
        "    try:\n",
        "        # Read FITS file\n",
        "        with fits.open(Path(input_dir) / 'temperature_map.fits') as hdul:\n",
        "            temperature_data = hdul[1].data\n",
        "\n",
        "            # Convert to DataFrame\n",
        "            temp_df = pd.DataFrame(temperature_data)\n",
        "            temp_df.to_csv(output_path / 'processed_temperature.csv', index=False)\n",
        "\n",
        "            logger.info('Processed temperature map')\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f'Error processing temperature map: {e}')\n",
        "\n",
        "# Standalone execution for testing\n",
        "if __name__ == '__main__':\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    download_wmap_data()\n",
        "    preprocess_wmap_data()"
      ],
      "metadata": {
        "id": "FwY_qFQNiSYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pandas as pd\n",
        "import sqlalchemy as sa\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from geoalchemy2 import Geometry\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "Base = declarative_base()\n",
        "\n",
        "class WMAPObservation(Base):\n",
        "    \"\"\"\n",
        "    SQLAlchemy model for WMAP observations\n",
        "    \"\"\"\n",
        "    __tablename__ = 'wmap_observations'\n",
        "\n",
        "    id = sa.Column(sa.Integer, primary_key=True)\n",
        "    frequency_band = sa.Column(sa.Float, nullable=False)\n",
        "    temperature = sa.Column(sa.Float, nullable=False)\n",
        "    sky_coordinate = sa.Column(Geometry('POINT'), nullable=False)\n",
        "    observation_time = sa.Column(sa.DateTime, nullable=False)\n",
        "    polarization = sa.Column(sa.Float)\n",
        "\n",
        "class DatabaseManager:\n",
        "    def __init__(self, db_config):\n",
        "        \"\"\"\n",
        "        Initialize database connection\n",
        "\n",
        "        Args:\n",
        "            db_config (dict): Database configuration parameters\n",
        "        \"\"\"\n",
        "        self.engine = sa.create_engine(\n",
        "            f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}/{db_config['database']}\"\n",
        "        )\n",
        "        self.Session = sessionmaker(bind=self.engine)\n",
        "\n",
        "    def create_schema(self):\n",
        "        \"\"\"\n",
        "        Create database schema\n",
        "        \"\"\"\n",
        "        try:\n",
        "            Base.metadata.create_all(self.engine)\n",
        "            logger.info(\"Database schema created successfully\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error creating schema: {e}\")\n",
        "\n",
        "    def import_data(self, data_path='data/processed/processed_temperature.csv'):\n",
        "        \"\"\"\n",
        "        Import processed WMAP data into database\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Path to processed CSV file\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Read processed data\n",
        "            df = pd.read_csv(data_path)\n",
        "\n",
        "            # Create session\n",
        "            session = self.Session()\n",
        "\n",
        "            # Convert DataFrame to database objects\n",
        "            observations = []\n",
        "            for _, row in df.iterrows():\n",
        "                obs = WMAPObservation(\n",
        "                    frequency_band=row.get('frequency', 0),\n",
        "                    temperature=row.get('temperature', 0),\n",
        "                    sky_coordinate=f'POINT({row.get(\"longitude\", 0)} {row.get(\"latitude\", 0)})',\n",
        "                    observation_time=pd.to_datetime(row.get('timestamp', pd.Timestamp.now())),\n",
        "                    polarization=row.get('polarization', None)\n",
        "                )\n",
        "                observations.append(obs)\n",
        "\n",
        "            # Bulk insert\n",
        "            session.add_all(observations)\n",
        "            session.commit()\n",
        "\n",
        "            logger.info(f\"Imported {len(observations)} observations\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error importing data: {e}\")\n",
        "        finally:\n",
        "            session.close()\n",
        "\n",
        "    def perform_advanced_query(self):\n",
        "        \"\"\"\n",
        "        Perform advanced SQL queries on WMAP data\n",
        "        \"\"\"\n",
        "        try:\n",
        "            session = self.Session()\n",
        "\n",
        "            # Example query: Find observations in specific frequency range\n",
        "            query = session.query(WMAPObservation).filter(\n",
        "                sa.and_(\n",
        "                    WMAPObservation.frequency_band.between(20, 100),\n",
        "                    WMAPObservation.temperature > 2.7\n",
        "                )\n",
        "            )\n",
        "\n",
        "            results = query.all()\n",
        "            logger.info(f\"Advanced query returned {len(results)} results\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in advanced query: {e}\")\n",
        "        finally:\n",
        "            session.close()\n",
        "\n",
        "# Standalone execution for testing\n",
        "if __name__ == '__main__':\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    # Example configuration\n",
        "    config = {\n",
        "        'host': 'localhost',\n",
        "        'database': 'wmap_database',\n",
        "        'user': 'astronomical_user',\n",
        "        'password': 'secure_password'\n",
        "    }\n",
        "\n",
        "    db_manager = DatabaseManager(config)\n",
        "    db_manager.create_schema()\n",
        "    db_manager.import_data()\n",
        "    db_manager.perform_advanced_query()"
      ],
      "metadata": {
        "id": "POIkddh2iUCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from astropy.coordinates import SkyCoord\n",
        "from astropy import units as u\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def perform_analysis(data_path='data/processed/processed_temperature.csv'):\n",
        "    \"\"\"\n",
        "    Perform comprehensive analysis of WMAP data\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to processed WMAP data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load data\n",
        "        df = pd.read_csv(data_path)\n",
        "\n",
        "        # Coordinate conversion\n",
        "        sky_coords = SkyCoord(\n",
        "            ra=df['longitude'] * u.degree,\n",
        "            dec=df['latitude'] * u.degree,\n",
        "            frame='icrs'\n",
        "        )\n",
        "\n",
        "        # Temperature analysis\n",
        "        temp_stats = {\n",
        "            'mean': df['temperature'].mean(),\n",
        "            'median': df['temperature'].median(),\n",
        "            'std_dev': df['temperature'].std()\n",
        "        }\n",
        "        logger.info(f\"Temperature Statistics: {temp_stats}\")\n",
        "\n",
        "        # Visualization: Temperature Distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(df['temperature'], bins=50, edgecolor='black')\n",
        "        plt.title('WMAP Temperature Distribution')\n",
        "        plt.xlabel('Temperature (K)')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.savefig('results/temperature_distribution.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Distributed Processing with Spark\n",
        "        spark_analysis(df)\n",
        "\n",
        "        return temp_stats\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Analysis error: {e}\")\n",
        "\n",
        "def spark_analysis(df):\n",
        "    \"\"\"\n",
        "    Perform distributed data processing using PySpark\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): Input DataFrame\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize Spark Session\n",
        "        spark = SparkSession.builder \\\n",
        "            .appName(\"WMAP Distributed Analysis\") \\\n",
        "            .getOrCreate()\n",
        "\n",
        "        # Convert Pandas DataFrame to Spark DataFrame\n",
        "        spark_df = spark.createDataFrame(df)\n",
        "\n",
        "        # Prepare data for clustering\n",
        "        feature_cols = ['longitude', 'latitude', 'temperature']\n",
        "        assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "        assembled_df = assembler.transform(spark_df)\n",
        "\n",
        "        # K-means clustering\n",
        "        kmeans = KMeans().setK(5).setSeed(42)\n",
        "        model = kmeans.fit(assembled_df)\n",
        "\n",
        "        # Get cluster centers\n",
        "        centers = model.clusterCenters()\n",
        "        logger.info(\"Cluster Centers:\")\n",
        "        for i, center in enumerate(centers):\n",
        "            logger.info(f\"Cluster {i}: {center}\")\n",
        "\n",
        "        spark.stop()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Spark analysis error: {e}\")\n",
        "\n",
        "def advanced_astropy_analysis(data_path='data/processed/processed_temperature.csv'):\n",
        "    \"\"\"\n",
        "    Advanced astrophysical analysis using Astropy\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to processed WMAP data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load data\n",
        "        df = pd.read_csv(data_path)\n",
        "\n",
        "        # Create SkyCoord object\n",
        "        coords = SkyCoord(\n",
        "            ra=df['longitude'] * u.degree,\n",
        "            dec=df['latitude'] * u.degree,\n",
        "            distance=df['temperature'] * u.kelvin\n",
        "        )\n",
        "\n",
        "        # Coordinate transformations\n",
        "        galactic_coords = coords.galactic\n",
        "\n",
        "        # Distance calculations\n",
        "        distance_stats = {\n",
        "            'mean_distance': np.mean(coords.distance),\n",
        "            'max_distance': np.max(coords.distance),\n",
        "            'min_distance': np.min(coords.distance)\n",
        "        }\n",
        "        logger.info(f\"Distance Statistics: {distance_stats}\")\n",
        "\n",
        "        # Visualization of Galactic Coordinates\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.scatter(\n",
        "            galactic_coords.l.degree,\n",
        "            galactic_coords.b.degree,\n",
        "            c=df['"
      ],
      "metadata": {
        "id": "OdGhmhLsiX2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}